<!DOCTYPE html><!--Author: Pranav Rajpurkar 2016--><html><head><meta charset="utf-8"><title>Background Aware Movie Conversations Dataset</title><meta name="description" content="Holl-E is a domain specific background aware conversations dataset"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no"><meta property="og:image" content="/logo.png"><link rel="image_src" type="image/png" href="/holl-e-website/logo.png"><link rel="shortcut icon" href="/holl-e-website/favicon.ico" type="image/x-icon"><link rel="icon" href="/holl-e-website/favicon.ico" type="image/x-icon"><link rel="stylesheet" href="/holl-e-website/bower_components/bootstrap/dist/css/bootstrap.min.css"><link rel="stylesheet" href="/holl-e-website/stylesheets/layout.css"><link rel="stylesheet" href="/holl-e-website/stylesheets/index.css"><script async defer src="https://buttons.github.io/buttons.js"></script><script src="/holl-e-website/javascripts/analytics.js"></script></head><body><div class="navbar navbar-default navbar-fixed-top" id="topNavbar" role="navigation"><div class="container clearfix" id="navContainer"><div class="rightNav"><div class="collapseDiv"><button class="navbar-toggle collapsed" type="button" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar"><span class="glyphicon glyphicon-menu-hamburger"></span></button></div><div class="collapse navbar-collapse" id="navbar"><ul class="nav navbar-nav navbar-right"><li><a href="/holl-e-website/">Home</a></li></ul></div></div><div class="leftNav"><div class="brandDiv"><a class="navbar-brand" href="/holl-e-website/">Holl-E</a></div></div></div></div><div class="cover" id="topCover"><div class="container"><div class="row"><div class="col-md-12"><h1 id="appTitle">Holl-E</h1><h2 id="appSubtitle">Background Aware Movie Conversations Dataset</h2></div></div></div></div><div class="cover" id="contentCover"><div class="container"><div class="row"><div class="col-md-5"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>What is Holl-E?</h2></div><p> <span> </span>Holl-E is a background aware movie conversations dataset consisting of ~9K chats with at least three background resources associated with the chat. Every alternate utterance is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie.              <a class="btn actionBtn" href="https://www.aclweb.org/anthology/D18-1255/">Holl-E paper (EMNLP 2018)</a></p><hr><div class="infoHeadline"><h2>Getting Started</h2></div><p> Download the dataset of 9k chats with at least three background resources per chat. <ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://drive.google.com/open?id=1xQBRDs5q_2xLOdOpbq7UeAmUM0Ht370A" download>Download dataset</a></li></ul></p><hr><div class="infoHeadline"><h2>Models</h2><p> </p><span>Our baselines consist of (1) pure generation based models which ignore the background knowledge (2) generation based models which learn to copy information from the background knowledge when required and (3) span prediction based models which predict the appropriate response span in the background knowledge. We also have different splits of the dataset to test different capabilities of new architectures. We also provide a multi-reference evaluation for our test set. Please see the code repository for more details.           </span><ul class="list-unstyled"><li><a class="btn actionBtn inverseBtn" href="https://github.com/nikitacs16/Holl-E" download>Code</a></li></ul></div><div class="infoHeadline"><h2>Have Questions?</h2></div><p> Ask us questions at   <a href="mailto:nikitamoghe29@gmail.com">nikitamoghe29@gmail.com</a>.</p></div><div class="infoSubheadline"><a href="https://twitter.com/share" class="twitter-share-button" data-url="https://iitmnlp.github.io/holl-e-website" data-text="Holl-E Dataset - Background Aware Movie Conversations Dataset" data-via="iitmnlp" data-size="large" data-hashtags="Holl-E">Tweet</a> <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script><!-- Place this tag where you want the button to render. -->
<a class="github-button" href="https://github.com/nikitacs16/Holl-E" data-icon="octicon-star" data-style="mega" data-count-href="/iitmnlp/DailyDialog-plusplus/stargazers" data-count-api="/repos/iitmnlp/DailyDialog-plusplus#stargazers_count" data-count-aria-label="# stargazers on GitHub" aria-label="Star iitmnlp/DailyDialog-plusplus on GitHub">Star</a></div></div></div><div class="col-md-7"><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Results: Response Generation (trained on oracle)</h2></div><p> Holl-E evaluates the ability of new architectures to produce responses grounded in knowledge. For a given context of the conversation, the task is to generate responses by copying and/or modifying contiguous segments from the background knowledge. The resources consist of the plot of the movie, review of the movie, some comments about the movie, or a fact table. We provide both the span-level annotation and the actual utterance for every alternate response. We use ROUGE-L and BLEU-4 as the performance measure. The other measures and human evaluation are discussed in the paper.  </p><table class="table performanceTable"><tr><th>Rank</th><th>Model</th><th>ROUGE-L</th><th>BLEU-4</th><tr><td><p>1</p><span class="date label label-default">Nov 21, 2019</span></td><td>GLKS<p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.09528.pdf">(Ren et al., '19)</a></td><td>38.69</td><td>NA</td></tr><tr><td><p>2</p><span class="date label label-default">Jun 16, 2019</span></td><td>CaKe <b><p class="institution">University of Amsterdam</p><a href="https://arxiv.org/abs/1906.06685">(Zhang et al. '19)</a></td><td>37.48</td><td>26.02</td></tr><tr><td><p>3</p><span class="date label label-default">Aug 18, 2019</span></td><td>RefNet <b><p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.06449v1.pdf">(Meng et al., '19)</a></td><td>37.11</td><td>27</td></tr><tr><td><p>4</p><span class="date label label-default">May 28, 2020</span></td><td>SSS BERT <b><p class="institution">IIT Madras</p><a href="https://arxiv.org/abs/2005.14315">(Moghe et al., '20)</a></td><td>35.2</td><td>22.78</td></tr><tr><td><p>5</p><span class="date label label-default">Sep 18, 2018</span></td><td>GTTP <b><p class="institution">Baseline</p><a href="https://arxiv.org/abs/1809.08205">(Moghe et al., '18)</a></td><td>25.67</td><td>13.92</td></tr></tr></table></div></div><div class="infoCard"><div class="infoBody"><div class="infoHeadline"><h2>Results: Response Generation (trained on mixed-long)</h2></div><p>  Here, we report the test perfromance of various models on the mixed-long version of the dataset. In this setup, all the background resources are provided as they are with the chat. This setup measures the ability of the system to retrieve the correct background resource first and then generate a response </p><table class="table performanceTable"><th>Rank</th><th>Model</th><th>ROUGE-L</th><th>BLEU-4</th><tr><td><p>1</p><span class="date label label-default">Nov 21, 2019</span></td><td>GLKS<p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.09528.pdf">(Ren et al., '19)</a></td><td>30.36</td><td>NA</td></tr><tr><td><p>2</p><span class="date label label-default">Aug 18, 2019</span></td><td>RefNet <b><p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.06449v1.pdf">(Meng et al., '19)</a></td><td>29.64</td><td>17.19</td></tr><tr><td><p>3</p><span class="date label label-default">Sep 18, 2018</span></td><td>GTTP <b><p class="institution">Baseline</p><a href="https://arxiv.org/abs/1809.08205">(Moghe et al., '18)</a></td><td>17.35</td><td>7.51</td></tr></table></div></div><div class="infoCard"><div class="infoBody"><div class="infoHeadline">             <h2>Results: Response Generation (trained on mixed-short)</h2></div><p>  Here, we report the test perfromance of various models on the mixed-short version of the dataset. In this setup, all the background resources are provided but such that the total number of tokens is limited to 256.</p><table class="table performanceTable"><th>Rank</th><th>Model</th><th>ROUGE-L</th><th>BLEU-4</th><tr><td><p>1</p><span class="date label label-default">Nov 21, 2019</span></td><td>GLKS<p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.09528.pdf">(Ren et al., '19)</a></td><td>39.63</td><td>NA</td></tr><tr><td><p>3</p><span class="date label label-default">Jun 16, 2019</span></td><td>CaKe <b><p class="institution">University of Amsterdam</p><a href="https://arxiv.org/abs/1906.06685">(Zhang et al. '19)</a></td><td>36.01</td><td>26.17</td></tr><tr><td><p>2</p><span class="date label label-default">Aug 18, 2019</span></td><td>RefNet <b><p class="institution">Shandong University + University of Amsterdam</p><a href="https://arxiv.org/pdf/1908.06449v1.pdf">(Meng et al., '19)</a></td><td>36.17</td><td>29.38</td></tr><tr><td><p>4</p><span class="date label label-default">Mar 25, 2019</span></td><td>AKGCM <b><p class="institution">Baidu Inc</p><a href="https://www.aclweb.org/anthology/D19-1187.pdf">(Liu et al., '20)</a></td><td>34.72</td><td>30.84</td></tr><tr><td><p>5</p><span class="date label label-default">Sep 18, 2018</span></td><td>GTTP <b><p class="institution">Baseline</p><a href="https://arxiv.org/abs/1809.08205">(Moghe et al., '18)</a></td><td>25.13</td><td>11.05</td></tr></table></div></div></div></div></div></div><nav class="navbar navbar-default navbar-static-bottom footer"><div class="container clearfix"><div class="rightNav"><div><ul class="nav navbar-nav navbar-right"><li><a href="/holl-e-website/">Holl-E</a></li></ul></div></div></div></nav><script src="/holl-e-website/bower_components/jquery/dist/jquery.min.js"></script><script src="/holl-e-website/bower_components/bootstrap/dist/js/bootstrap.min.js"></script></body></html>